# å¿«é€Ÿå¼€å§‹

é€šè¿‡è¿™ä¸ªç²¾ç®€çš„å·¥ä½œæµç¨‹ï¼Œå¿«é€Ÿè·å¾— Probing çš„ä»·å€¼ã€‚

## 5 åˆ†é’Ÿä¸Šæ‰‹

### æ­¥éª¤ 1ï¼šè®¾ç½®ç›®æ ‡è¿›ç¨‹

æ‰€æœ‰ Probing å‘½ä»¤éƒ½éœ€è¦ä¸€ä¸ªç›®æ ‡ç«¯ç‚¹ã€‚å°† `$ENDPOINT` è®¾ç½®ä¸ºæœ¬åœ°è¿›ç¨‹ ID æˆ–è¿œç¨‹åœ°å€ï¼š

```bash
# æœ¬åœ°è¿›ç¨‹ - æŸ¥æ‰¾å¹¶è®¾ç½® Python è¿›ç¨‹ ID
export ENDPOINT=$(pgrep -f "python.*your_script")

# æˆ–è€…è¿œç¨‹è¿›ç¨‹
export ENDPOINT=remote-host:8080
```

!!! tip "æŸ¥æ‰¾è¿›ç¨‹"
    ä½¿ç”¨ `ps aux | grep python` æˆ– `pgrep -f "python.*train"` æ¥å®šä½ç›®æ ‡è¿›ç¨‹ã€‚

### æ­¥éª¤ 2ï¼šè¿æ¥å¹¶æ¢ç´¢

```bash
# è¿æ¥åˆ°è¿›ç¨‹ï¼ˆä»… Linuxï¼‰
probing $ENDPOINT inject

# è·å–åŸºæœ¬è¿›ç¨‹ä¿¡æ¯
probing $ENDPOINT eval "import os, psutil; proc = psutil.Process(); print(f'PID: {os.getpid()}, å†…å­˜: {proc.memory_info().rss/1024**2:.1f}MB')"
```

### æ­¥éª¤ 3ï¼šå°è¯•ä¸‰å¤§æ ¸å¿ƒåŠŸèƒ½

#### ğŸ“Š æŸ¥è¯¢ç»“æ„åŒ–æ•°æ®

```bash
probing $ENDPOINT query "SELECT name, value FROM information_schema.df_settings LIMIT 5"
```

#### ğŸ¯ æ‰§è¡Œå®æ—¶ä»£ç 

```bash
probing $ENDPOINT eval "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

#### ğŸ” æ•è·æ‰§è¡Œä¸Šä¸‹æ–‡

```bash
probing $ENDPOINT backtrace

probing $ENDPOINT query "SELECT func, file, lineno FROM python.backtrace ORDER BY depth LIMIT 5"
```

## ä¸‰å¤§æ ¸å¿ƒèƒ½åŠ›

Probing æä¾›ä¸‰ä¸ªå¼ºå¤§çš„èƒ½åŠ›ï¼Œå®ƒä»¬ååŒå·¥ä½œï¼š

### ğŸ¯ evalï¼šåœ¨è¿è¡Œä¸­çš„è¿›ç¨‹æ‰§è¡Œä»£ç 

ç›´æ¥åœ¨ç›®æ ‡è¿›ç¨‹ä¸­è¿è¡Œä»»æ„ Python ä»£ç ï¼š

```bash
# æ£€æŸ¥è®­ç»ƒçº¿ç¨‹
probing $ENDPOINT eval "import threading; [print(f'{t.name}: {t.is_alive()}') for t in threading.enumerate()]"

# æ£€æŸ¥ GPU å†…å­˜ä½¿ç”¨
probing $ENDPOINT eval "import torch; print(f'GPU: {torch.cuda.memory_allocated()/1024**3:.1f}GB å·²åˆ†é…')"
```

### ğŸ“Š queryï¼šç”¨ SQL åˆ†ææ•°æ®

ä½¿ç”¨ç†Ÿæ‚‰çš„ SQL è¯­æ³•æŸ¥è¯¢ç»“æ„åŒ–æ€§èƒ½æ•°æ®ï¼š

```bash
probing $ENDPOINT query "
SELECT
    step,
    module,
    SUM(allocated) as total_memory_mb,
    COUNT(*) as operation_count
FROM python.torch_trace
WHERE step > 100
GROUP BY step, module
ORDER BY total_memory_mb DESC
LIMIT 10"
```

### ğŸ” backtraceï¼šå¸¦å †æ ˆä¸Šä¸‹æ–‡çš„è°ƒè¯•

æ•è·å¸¦æœ‰ Python å˜é‡å€¼çš„è¯¦ç»†è°ƒç”¨æ ˆï¼š

```bash
# æ•è·å½“å‰è°ƒç”¨æ ˆ
probing $ENDPOINT backtrace

# æŸ¥è¯¢å †æ ˆè·Ÿè¸ª
probing $ENDPOINT query "SELECT func, file, lineno FROM python.backtrace ORDER BY depth LIMIT 3"
```

## çœŸå®è°ƒè¯•åœºæ™¯

### åœºæ™¯ 1ï¼šè®­ç»ƒè¿›ç¨‹å¡ä½

**é—®é¢˜**ï¼šPyTorch è®­ç»ƒçªç„¶åœæ­¢è¿›å±•ã€‚

```bash
# 1. æŸ¥çœ‹ä¸»çº¿ç¨‹åœ¨åšä»€ä¹ˆ
probing $ENDPOINT backtrace

# 2. æ£€æŸ¥çº¿ç¨‹çŠ¶æ€
probing $ENDPOINT eval "import threading; [(t.name, t.is_alive()) for t in threading.enumerate()]"

# 3. åˆ†æå †æ ˆä¸Šä¸‹æ–‡
probing $ENDPOINT query "SELECT func, file, lineno FROM python.backtrace ORDER BY depth LIMIT 10"
```

### åœºæ™¯ 2ï¼šå†…å­˜æ³„æ¼æ’æŸ¥

**é—®é¢˜**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­å†…å­˜ä½¿ç”¨æŒç»­å¢é•¿ã€‚

```bash
# å¼ºåˆ¶æ¸…ç†å¹¶è·å–å½“å‰çŠ¶æ€
probing $ENDPOINT eval "import gc, torch; gc.collect(); torch.cuda.empty_cache()"

# åˆ†æåˆ†é…è¶‹åŠ¿
probing $ENDPOINT query "SELECT step, AVG(allocated) as avg_memory FROM python.torch_trace GROUP BY step ORDER BY step"
```

### åœºæ™¯ 3ï¼šæ€§èƒ½ç“¶é¢ˆåˆ†æ

**é—®é¢˜**ï¼šéœ€è¦æ‰¾å‡ºå“ªäº›æ¨¡å‹ç»„ä»¶æœ€æ…¢ã€‚

```bash
# æŸ¥æ‰¾æœ€è€—æ—¶çš„æ“ä½œ
probing $ENDPOINT query "
SELECT module, stage, AVG(duration) as avg_duration
FROM python.torch_trace
GROUP BY module, stage
ORDER BY avg_duration DESC
LIMIT 10"
```

## ä¸‹ä¸€æ­¥

- [SQL åˆ†æ](guide/sql-analytics.zh.md) - é«˜çº§æŸ¥è¯¢æŠ€å·§
- [å†…å­˜åˆ†æ](guide/memory-analysis.zh.md) - æ·±å…¥å†…å­˜è°ƒè¯•
- [è°ƒè¯•æŒ‡å—](guide/debugging.zh.md) - ä¸“å®¶çº§è°ƒè¯•æ¨¡å¼
